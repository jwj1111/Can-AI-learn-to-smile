{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc74f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9708c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(path=r'data\\all.jsonl'):\n",
    "    text_list=[]\n",
    "    with open(path,'r',encoding='utf-8') as infile:\n",
    "        for line in infile:\n",
    "            line_dict=json.loads(line.strip())\n",
    "            text_list.append(line_dict['answer_zh'])\n",
    "    print(\"data loaded\")\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a1c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_emoji(text_list):\n",
    "    emoji_pattern=re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U0001F300-\\U0001F5FF\"\n",
    "        u\"\\U0001F680-\\U0001F6FF\"\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "        u\"\\U00002700-\\U000027BF\"\n",
    "        u\"\\U0001F900-\\U0001F9FF\"\n",
    "        u\"\\U00002600-\\U000026FF\"\n",
    "        \"]\",flags=re.UNICODE)\n",
    "    pattern=re.compile(r'(.*?)('+emoji_pattern.pattern+r'+)')\n",
    "    results=[]\n",
    "    for text in tqdm(text_list,total=len(text_list),desc='txt/emoji parsing...'):\n",
    "        paras=text.split('\\n\\n')\n",
    "        for para in paras:\n",
    "            matches=pattern.findall(para)\n",
    "            if matches:\n",
    "                for txt,emo in matches:\n",
    "                    full_txt=txt+emo\n",
    "                    results.append({\n",
    "                        \"emoji\":emo,\n",
    "                        \"txt\":txt,\n",
    "                        \"full_txt\":full_txt\n",
    "                    })\n",
    "    with open(r'data\\extract_text_emoji_result.jsonl','w',encoding='utf-8') as outfile:\n",
    "        for result in results:\n",
    "            outfile.write(json.dumps(result,ensure_ascii=False)+'\\n')\n",
    "    print('txt/emoji parsing result saved as data/extract_text_emoji_result.jsonl')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e6db872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_sentiment_tagging(model_name,results):\n",
    "    dic_results=copy.deepcopy(results)\n",
    "    tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
    "    model=AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    id2label=model.config.id2label\n",
    "    for dic_result in tqdm(dic_results,total=len(dic_results),desc='txt sentiment tagging...'):\n",
    "        txt=dic_result['txt']\n",
    "        inputs=tokenizer(txt,return_tensors='pt',padding=True,truncation=True)\n",
    "        inputs={key:value.to(device) for key,value in inputs.items()}\n",
    "        with torch.inference_mode():\n",
    "            outputs=model(**inputs)\n",
    "            predictions=outputs.logits.argmax(dim=-1).item()\n",
    "            sentiment_tag=id2label[predictions]\n",
    "        dic_result['txt_senti']=sentiment_tag\n",
    "    with open(r'data\\txt_sentiment_tagging_result.jsonl','w',encoding='utf-8') as outfile:\n",
    "        for dic_result in dic_results:\n",
    "            outfile.write(json.dumps(dic_result,ensure_ascii=False)+'\\n')\n",
    "    print('txt sentiment tagging result saved as data/txt_sentiment_tagging_result.jsonl')\n",
    "    return dic_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67112114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_conflict(emoji_senti,txt_senti):\n",
    "    if (emoji_senti=='positive' and txt_senti=='negative') or (emoji_senti=='negative' and txt_senti=='positive'):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c08bc101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_sentiment_tagging(dic_results,lexicon_path=r'data\\train-00000-of-00001-5a3ca3bbb3cb2c22.parquet'):\n",
    "    lexicon_df=pd.read_parquet(lexicon_path)\n",
    "    emoji_senti_dict={}\n",
    "    emoji_name_dict={}\n",
    "    for _,row in lexicon_df.iterrows():\n",
    "        if row['Emoji'] and row['label'] and row['Unicode_Name']:\n",
    "            emoji_senti_dict[row['Emoji']]='positive' if row['label']==2 else 'neutral' if row['label']==1 else 'negative'\n",
    "            emoji_name_dict[row['Emoji']]=row['Unicode_Name']\n",
    "    mydf=pd.DataFrame(dic_results)\n",
    "    mydf[\"emoji_name\"]=mydf[\"emoji\"].map(emoji_name_dict)\n",
    "    mydf[\"emoji_senti\"]=mydf[\"emoji\"].map(emoji_senti_dict)\n",
    "    print('emoji sentiment tagged')\n",
    "    mydf[\"conflict\"]=mydf.apply(lambda row: is_conflict(row['emoji_senti'],row['txt_senti']),axis=1)\n",
    "    print('sentiment conflict analyzed')\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_counts(df_tagged):\n",
    "    mydf=df_tagged.copy()\n",
    "    mydf[\"emoji_count\"]=mydf[\"emoji\"].map(mydf[\"emoji\"].value_counts())\n",
    "    mydf_sorted=mydf.sort_values(by=\"emoji_count\",ascending=False)\n",
    "    print('emoji count finished')\n",
    "    mydf_arranged=mydf_sorted[['emoji','emoji_name','emoji_count','emoji_senti','txt_senti','conflict','txt','full_txt']]\n",
    "    mydf_cleaned=mydf_arranged.dropna()\n",
    "    mydf_cleaned2=mydf_cleaned[mydf_cleaned['txt'].str.strip()!='']\n",
    "    os.makedirs('result',exist_ok=True)\n",
    "    mydf_cleaned2.to_csv(r'result\\result_final.csv',index=False,encoding='utf-8-sig')\n",
    "    print('result_final saved: result/result_final.csv')\n",
    "    return mydf_cleaned2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(mydf_final,path=r'result\\report_final.csv'):\n",
    "    total_count=len(mydf_final)\n",
    "    summary_df=mydf_final.groupby('emoji').agg(name=('emoji_name','first'),senti=('emoji_senti','first'),count=('emoji_count','first'),conflict_rate=('conflict','mean')).reset_index()\n",
    "    summary_df['use_percentage']=summary_df['count']/total_count\n",
    "    summary_df=summary_df.sort_values(by=['count','name'],ascending=False)\n",
    "    summary_df.to_csv(path,index=False,encoding='utf-8-sig')\n",
    "    print('report final saved: result/report_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "530f664c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "text_list=load_text(path=r'data\\all.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64646788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "txt/emoji parsing...: 100%|██████████| 2449/2449 [00:00<00:00, 4635.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt/emoji parsing result saved as data/extract_text_emoji_result.jsonl\n"
     ]
    }
   ],
   "source": [
    "results=extract_text_emoji(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "971c7afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "txt sentiment tagging...:   0%|          | 0/16550 [00:00<?, ?it/s]d:\\anaconda3\\Lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:371: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "txt sentiment tagging...: 100%|██████████| 16550/16550 [02:31<00:00, 109.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt sentiment tagging result saved as data/txt_sentiment_tagging_result.jsonl\n"
     ]
    }
   ],
   "source": [
    "dic_results=txt_sentiment_tagging(model_name=\"clapAI/roberta-large-multilingual-sentiment\",results=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb141a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji sentiment tagged\n",
      "sentiment conflict analyzed\n"
     ]
    }
   ],
   "source": [
    "df_tagged=emoji_sentiment_tagging(dic_results=dic_results,lexicon_path=r'data\\train-00000-of-00001-5a3ca3bbb3cb2c22.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97ca5487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji count finished\n"
     ]
    }
   ],
   "source": [
    "mydf_final=emoji_counts(df_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab31323",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_report(mydf_final,path=r'result\\report_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
